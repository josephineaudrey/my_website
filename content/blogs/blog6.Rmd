---
title: 'Employee Data'
author: "Josephine Haag"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    highlight: zenburn
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---


```{r, setup}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(fivethirtyeight)
library(here)
library(skimr)
library(janitor)
library(vroom)
library(tidyquant)
library(patchwork)

```



# Where Do People Drink The Most Beer, Wine And Spirits?


```{r load_alcohol_data}
library(fivethirtyeight)
data(drinks)

```



```{r glimpse_skim_data}
skim(drinks)
```
What are the variable types? Any missing values we should worry about?

Answer:

Variable types : character, numeric
There are no missing values

```{r beer_plot}

top25_beer_plot <- drinks %>% 
  top_n(25, beer_servings) %>% #ranked top 25 by beer servings
  ggplot(aes(
    x = beer_servings,
    y = reorder(country,beer_servings) #Ordered countries by beer servings
  )) +
  geom_col() +
  labs(
    x = "Beer Servings", 
    y = "Country", 
    title = "Top 25 Beer Consuming Countries") + #added labels to axis and title
  theme_minimal() +
  NULL

top25_beer_plot


```


```{r wine_plot}

#copied top 25 beer plot and replaced beer with wine
top25_wine_plot <- drinks %>% 
  top_n(25, wine_servings) %>% 
  ggplot(aes(
    x = wine_servings,
    y = reorder(country,wine_servings)
  )) +
  geom_col() +
  labs(
    x = "Wine Servings", 
    y = "Country", 
    title = "Top 25 Wine Consuming Countries") + 
  theme_minimal() +
  NULL

top25_wine_plot


```

```{r spirit_plot}

#copied top 25 beer plot and replaced beer with spirit
top25_spirit_plot <- drinks %>% 
  top_n(25, spirit_servings) %>% 
  ggplot(aes(
    x = spirit_servings,
    y = reorder(country,spirit_servings)
  )) +
  geom_col() +
  labs(
    x = "Spirit Servings", 
    y = "Country", 
    title = "Top 25 Spirit Consuming Countries") + 
  theme_minimal() +
  NULL

top25_spirit_plot

```

> IMPLICATIONS

- In the wine consumption rankings, 9 of the top 10 are European countries. Most areas of Europe (especially the low latitudes) are very suitable for growing grapes due to sufficient sunlight and fertile soil. The typical ones are Southern France, Portugal, Andorra, Italy, and Greece. This may develop the people's habit of drinking wine. Compared to wine, the high beer consuming countries are mainly in higher latitudes (north of the Alps), since wheat is widely planted and is an important raw material for beer in these countries. In addition, the beer ranking includes the most continents among other liquors, which may implicate that beer is the most widely accepted and accessible alcohol in the world.
- In the spirits consumption ranking, six of the top 25 are island countries in the Caribbean and the Pacific, and 11 of the top 25 are East European countries. This conforms to the origins of two very famous spirit types - rum and vodka.


# Analysis of movies- IMDB dataset

  
```{r load_movies_data}

movies <- read_csv("movies.csv")
glimpse(movies)

```

## Use your data import, inspection, and cleaning skills to answer the following:

```{r skim_movies_data}
skim(movies)
```
- Are there any missing values (NAs)? Are all entries distinct or are there duplicate entries?

>Answer

  -missing values (NA) = 0
  -Duplicates entries = 0

        
- Produce a table with the count of movies by genre, ranked in descending order

```{r kable_movies_by_genre}

library(kableExtra)

kable_movies_by_genre <- kbl(movies%>% distinct() %>% 
  group_by(genre)%>%
  count(genre)%>%
  arrange(desc(n)))%>%
  kable_styling(bootstrap_options=c("striped","hover","condensed","responsive")) #Used kable function for read-friendly table

kable_movies_by_genre

```


- Produce a table with the average gross earning and budget (`gross` and `budget`) by genre.
Calculate a variable `return_on_budget` which shows how many \$ did a movie make at the box office for each \$ of its budget. Ranked genres by this `return_on_budget` in descending order

```{r average_gross_and_budget_by_genre}

library(docxtools)
options(scipen=999)
average_gross_and_budget_by_genre <- kbl(movies %>% 
 group_by(genre) %>% 
 summarise(mean_gross = mean(gross), #Summarised to get mean gross earnings
            mean_budget = mean(budget)) %>% #summarised to get mean budget
 mutate(return_on_budget = mean_gross/mean_budget) %>% #added column for return on budget.
 arrange(desc(return_on_budget))) %>% #arranged table in descending order of return on budget
 kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))

average_gross_and_budget_by_genre

```

- Produce a table that shows the top 15 directors who have created the highest gross revenue in the box office. Don't just show the total gross amount, but also the mean, median, and standard deviation per director.
```{r top15_directors}
options(scipen=999)
top15_directors <- kbl(movies %>% group_by(director) %>%
  summarise(total_gross_director = sum(gross),
            mean_director = mean(gross),
            median_director = median(gross),
            sd_director = sd(gross)) %>%
  slice_max(order_by = total_gross_director,n = 15)) %>% #used slice_max to select top 15 directors by total gross.
  kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))

top15_directors

```


- Finally, ratings. Produce a table that describes how ratings are distributed by genre. We don't want just the mean, but also, min, max, median, SD and some kind of a histogram or density graph that visually shows how ratings are distributed. 

Histogram Graph:
```{r ratings_table_and_graph ,fig.width=40,fig.height=10}

ratings_table <- movies %>% #Assigned the requested variables to ratings table
  group_by(genre) %>%
  summarise(mean_rating = mean(rating),
            median_rating = median(rating),
            sd_rating = sd(rating),
            min_rating = min(rating),
            max_rating = max(rating))

rating_graph <- ggplot(ratings_table, aes(#Used ratings table to plot graph
  x = reorder(genre, -mean_rating), #reordered genre by descendin mean rating
  y = mean_rating
  )) +
  geom_col(width=0.7, position=position_dodge(width=0.8)) +
  labs(
    x = "Genre", 
    y = "Mean Ratings", 
    title = "Ratings by Genre") +
  theme_minimal() +
  theme(text = element_text(size=40))+
  NULL

kbl(ratings_table) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed","responsive")) #printed table with kable function
rating_graph #printed graph

```


```{r skim_movies}
skim(movies)
```


## Use `ggplot` to answer the following

  - Examine the relationship between `gross` and `cast_facebook_likes`. Produce a scatterplot and write one sentence discussing whether the number of facebook likes that the cast has received is likely to be a good predictor of how much money a movie will make at the box office. What variable are you going to map to the Y- and X- axes?
  
  
```{r gross_on_fblikes}
gross_on_fblikes <- ggplot(movies, aes(x = cast_facebook_likes, y = gross)) + #chose likes on the x-axis, because hypothetically likes influence gross sales and not the other way around
  geom_point(alpha = 0.2) + 
  scale_x_log10() + #applied log scale on both axis to get a better view of the data in the plot
  scale_y_log10() + 
  geom_smooth(method = lm) + # applied geom smooth to get a trend line
  labs(
    title = "Relationship between Facebook likes and gross earnings",
    x = "Facebook likes",
    y = "Gross earning"
  ) +
  theme_minimal() + 
  NULL

gross_on_fblikes

```
  >Answer
  
  - We use "cast_facebook_likes" to map the the X-axes and "gross" to map the Y-axes. 
  - The number of facebook likes that the cast has received can predicts the gross box office. The more facebook likes the movie's cast receives, the more money it will make. However, the positive correlation is not very strong, since given the same "cast_facebook_likes", the deviation of "gross" is quite large, which makes the fitted correlation contain large errors.
  
  - Examine the relationship between `gross` and `budget`. Produce a scatterplot and write one sentence discussing whether budget is likely to be a good predictor of how much money a movie will make at the box office.

```{r gross_on_budget}
gross_on_budget <- ggplot(movies, aes(
  x = budget, 
  y = gross
  )) + 
  geom_point(alpha = 0.2) + 
  scale_x_log10() + 
  scale_y_log10() + 
  geom_smooth(method = lm) + 
  labs(
    title = "Relationship between gross earnings and budget",
    x = "Budget",
    y = "Gross earnings"
  ) +
  theme_minimal() +
  NULL

gross_on_budget

```
  >Answer
  
  Budget is likely to be a good predictor, since most of the data points are distributed closely near to the fitted line, especially in the upper right corner of the plot.
  
  - Examine the relationship between `gross` and `rating`. Produce a scatterplot, faceted by `genre` and discuss whether IMDB ratings are likely to be a good predictor of how much money a movie will make at the box office. Is there anything strange in this dataset?

```{r gross_on_rating}

gross_on_rating_plot <-ggplot(movies %>% 
  distinct(), #Used distinct function to remove duplicate rows                               
       aes(
       x = rating, 
       y = gross
       )) + 
  geom_point(alpha = 0.2) + 
  scale_x_log10() + 
  scale_y_log10() + 
  facet_wrap(~genre) + #faceted the graphs per genre
  geom_smooth(method = lm) + 
  labs(
    title = "Relationship between rating and gross earnings",
    x = "Rating",
    y = "Gross earnings"
  ) +
  theme_minimal() +
  NULL

gross_on_rating_plot

```
>Answer

- For action, adventure, animation, biography, fantasy, and horror movies, IMDB ratings are good predictors, since the distance between data points and the fitted line are rather short, which means the fitted line contains less errors. While for comedy, crime, drama and Sci-Fi movies, the correlation between two variables are rather weak. For some genres, the data are not abundant enough to prove correlations (i.e. family, musical, romance, thriller and western).
- There is something strange in this dataset. Some entries are almost the same to each other(titles, directors, year, etc. are all the same) except for votes.

# Returns of financial stocks


```{r load_nyse_data, message=FALSE, warning=FALSE}
nyse <- read_csv("nyse.csv")
glimpse(nyse)
```

Based on this dataset, create a table and a bar plot that shows the number of companies per sector, in descending order

```{r companies_per_sector,fig.width=20}

companies_per_sector_table <- kbl(nyse %>% 
  group_by(sector) %>%
  count(sector) %>%
  arrange(desc(n))) %>%
  kable_styling(bootstrap_options=c("striped","hover","condensed","responsive"))

companies_per_sector_plot <- ggplot(nyse %>% 
  group_by(sector) %>%
  count(sector) %>%
  arrange(desc(n)), aes(
    x = reorder(sector,-n), 
    y = n
    )) + 
  geom_col() + 
   theme_minimal() +
   labs(
     title = "Companies per sector",
     x = "Sector",
     y = "no. of companies"
   ) +
  NULL

companies_per_sector_table
companies_per_sector_plot

```


```{r get_price_data, message=FALSE, warning=FALSE, cache=TRUE}

myStocks <- c("BABA","MMM","ABB","ABT","ALC","SPY" ) %>%
  tq_get(get  = "stock.prices",
         from = "2011-01-01",
         to   = "2020-08-31") %>%
  group_by(symbol) 

glimpse(myStocks) # examine the structure of the resulting data frame
```


```{r calculate_returns, message=FALSE, warning=FALSE, cache=TRUE}
#calculate daily returns
myStocks_returns_daily <- myStocks %>%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = "daily", 
               type       = "log",
               col_rename = "daily_returns",
               cols = c(nested.col))  

#calculate monthly  returns
myStocks_returns_monthly <- myStocks %>%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = "monthly", 
               type       = "arithmetic",
               col_rename = "monthly_returns",
               cols = c(nested.col)) 

#calculate yearly returns
myStocks_returns_annual <- myStocks %>%
  group_by(symbol) %>%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = "yearly", 
               type       = "arithmetic",
               col_rename = "yearly_returns",
               cols = c(nested.col))
```


```{r summarise_monthly_returns}

summarise_monthly_returns_table <- myStocks_returns_monthly %>%
  summarise(min_monthly = min(monthly_returns), 
            max_monthly = max(monthly_returns), 
            median_monthly = median(monthly_returns), 
            mean_monthly = mean(monthly_returns), 
            SD_monthly = sd(monthly_returns))

kbl(summarise_monthly_returns_table) %>% 
  kable_styling(bootstrap_options=c("striped","hover","condensed","responsive"))

```


```{r density_monthly_returns}

density_monthly_returns <- ggplot(myStocks_returns_monthly, aes(
  x = monthly_returns)) + 
  geom_density() + 
  facet_wrap(~symbol) +
  labs(
    title = "Density of monthly stock returns",
    x = "Monthly returns"
  ) +
  theme_minimal() +
  NULL

density_monthly_returns

```

What can you infer from this plot? Which stock is the riskiest? The least risky? 

Answer:

The density plots show that the distribution of expected returns is approximately bell-shaped, which indicates that the return of the stocks of our choices is fairly close to normal distribution. The flatter the curve, the larger the standard deviation, namely the risk of a stock.
From the graphs we can see that Alibaba(BABA) is the riskiest, and S&P 500 (SPY) is the least risky.


```{r risk_return_plot}

risk_return_plot <- ggplot(myStocks_returns_monthly %>%
  summarise(
          expected_return = mean(monthly_returns),
          risk = sd(monthly_returns)),
  aes(
          x = risk, 
          y = expected_return, 
          label = symbol)) + 
  geom_point() +   
  ggrepel::geom_text_repel() +
  labs(
    title = "Risk vs. expected return",
    x = "Risk",
    y = "Expected return"
  ) + 
  theme_minimal() +
  NULL

risk_return_plot

```

What can you infer from this plot? Are there any stocks which, while being riskier, do not have a higher expected return?

Answer:

If we draw a line between the origin and each point, we can get the slopes of the points. The slopes indicate that for each unit of risk, how much return we can get from a specific stock. From the graph we can see that the slope of SPY is the steepest, and the rest of the stocks have flatter slopes, meaning that these stocks are riskier but do not render a higher expected return.


# On your own: IBM HR Analytics


```{r loading_HR_dataset}

hr_dataset <- read_csv( "datasets_1067_1925_WA_Fn-UseC_-HR-Employee-Attrition.csv")
glimpse(hr_dataset)

```

```{r cleaning_HR_dataset}

hr_cleaned <- hr_dataset %>% 
  clean_names() %>% 
  mutate(
    education = case_when(
      education == 1 ~ "Below College",
      education == 2 ~ "College",
      education == 3 ~ "Bachelor",
      education == 4 ~ "Master",
      education == 5 ~ "Doctor"
    ),
    environment_satisfaction = case_when(
      environment_satisfaction == 1 ~ "Low",
      environment_satisfaction == 2 ~ "Medium",
      environment_satisfaction == 3 ~ "High",
      environment_satisfaction == 4 ~ "Very High"
    ),
    job_satisfaction = case_when(
      job_satisfaction == 1 ~ "Low",
      job_satisfaction == 2 ~ "Medium",
      job_satisfaction == 3 ~ "High",
      job_satisfaction == 4 ~ "Very High"
    ),
    performance_rating = case_when(
      performance_rating == 1 ~ "Low",
      performance_rating == 2 ~ "Good",
      performance_rating == 3 ~ "Excellent",
      performance_rating == 4 ~ "Outstanding"
    ),
    work_life_balance = case_when(
      work_life_balance == 1 ~ "Bad",
      work_life_balance == 2 ~ "Good",
      work_life_balance == 3 ~ "Better",
      work_life_balance == 4 ~ "Best"
    )
  ) %>% 
  select(age, attrition, daily_rate, department,
         distance_from_home, education,
         gender, job_role,environment_satisfaction,
         job_satisfaction, marital_status,
         monthly_income, num_companies_worked, percent_salary_hike,
         performance_rating, total_working_years,
         work_life_balance, years_at_company,
         years_since_last_promotion)

```


1. How often do people leave the company (`attrition`)
```{r company_attrition_rate}
glimpse(hr_cleaned)


attrition_rate <- filter(hr_cleaned %>% 
         group_by(attrition) %>% 
         summarise(n = count(attrition)) %>% 
         mutate(attrition_rate = (n*100)/sum(n)), attrition == "Yes") #added column for the attrition rate %

attrition_rate

```

Answer:
The attrition rate is 16.1%.

2. How are `age`, `years_at_company`, `monthly_income` and `years_since_last_promotion` distributed? can you roughly guess which of these variables is closer to Normal just by looking at summary statistics? 

```{r HR_plots}
skim(hr_cleaned)

age_density <- ggplot(hr_cleaned, aes(age)) + 
  geom_density() + 
  labs(
    title = "Distribution of age",
    x = "Age"
  ) +
  theme_minimal() +
  NULL

years_at_company_density <- ggplot(hr_cleaned, aes(years_at_company)) + 
  geom_density() + 
  labs(
    title = "Distribution of years at company",
    x = "Years at company"
  ) +
  theme_minimal() +
  NULL

monthly_income_density <-ggplot(hr_cleaned, aes(monthly_income)) + 
  geom_density() +
  labs(
    title = "Distribution of monthly income",
    x = "Monthly income"
  ) +
  theme_minimal() +
  NULL

years_since_promotion <- ggplot(hr_cleaned, aes(years_since_last_promotion)) + 
  geom_density() +
  labs(
    title = "Distribution of years since promotion",
    x = "Years since promotion"
  ) +
  theme_minimal() +
  NULL

age_density
years_at_company_density
monthly_income_density
years_since_promotion


```


Answer:

We can look at how close the mean is to the 50th percentile and the relative positions of 25th and 75th percentiles are to the 50th percentile.`age` is close to normal distribution, while `years_at_company`, `monthly_income` and `years_since_last_promotion` are right screwed, with most small values in the left hand, a few large values in the right. 


3. How are `job_satisfaction` and `work_life_balance` distributed? Don't just report counts, but express categories as % of total

```{r job_sat_and_worklife_balance}


job_sat <- hr_cleaned %>% 
  group_by(job_satisfaction) %>% 
  summarise(n = count(job_satisfaction)) %>% 
  mutate(job_sat_perc = (n*100)/sum(n))

work_life_balance <- hr_cleaned %>% 
  group_by(work_life_balance) %>% 
  summarise(n = count(work_life_balance)) %>% 
  mutate(work_life_perc = (n*100)/sum(n)) %>% 
  arrange(desc(work_life_perc))

kbl(job_sat) %>% 
  kable_styling(bootstrap_options=c("striped","hover","condensed","responsive"))
kbl(work_life_balance) %>% 
  kable_styling(bootstrap_options=c("striped","hover","condensed","responsive"))

```

Answer:

`job_satisfaction` is right skewed, with around 60% of the values on the right.
`work_life_balance` seems to better resemble a normal distribution, a bit skewed to the right.


4. Is there any relationship between monthly income and education? Monthly income and gender?
```{r monthly_income_gender_education_plots, fig.width=20}
library(hrbrthemes)
options("scipen"=100, "digits"=4)

monthly_income_education_plot <- ggplot(hr_cleaned,
   aes(
     x = education, 
     y = monthly_income 
   )) + 
  geom_col() +
  theme_minimal() +
  theme(text = element_text(size=40))+
  labs(
    title = "Monthly income vs. education",
    x = "Monthly income",
    y = "Education"
  ) +
  NULL

monthly_income_gender_plot <- ggplot(hr_cleaned,
   aes(
     x = gender, 
     y = monthly_income 
   )) + 
  geom_col() +
  theme_minimal() +
  theme(text = element_text(size=30))+
  labs(
    title = "Monthly income vs. gender",
    x = "Monthly income",
    y = "Gender"
  ) +
  NULL

monthly_income_education_plot
monthly_income_gender_plot

```

Answer:

- There is an inverted U-shaped relationship between education and monthly income. Bachelors' income is higher than college's and under college's, since most of the high-payment jobs require at least bachelor's degrees. And Bachelors' income is also greater than masters' and PhDs' income, probably because given they all meet most companies' basic education requirement, bachelors always have more working experience since they step into careers earlier.
- Male monthly incomes are higher than female. Gender inequality is still very common in job markets.


5. Plot a boxplot of income vs job role. Make sure the highest-paid job roles appear first
```{r income_jobrole_boxplot, fig.width=40, fig.height=20}

income_jobrole_boxplot <- ggplot(hr_cleaned, 
       aes(
         x= reorder(job_role, -monthly_income), 
         y = monthly_income)) + 
  geom_boxplot() +
  labs(
    title = "Income per job role",
    x = "Job role",
    y = "Income"
  ) +
  theme_minimal() +
  theme(text = element_text(size=30))+
  NULL

income_jobrole_boxplot

```


6. Calculate and plot a bar chart of the mean (or median?) income by education level.

```{r barchart_income_education}
Education_mean_income_bar <- ggplot(hr_cleaned, aes(
    x = education, 
    y = mean(monthly_income
    ))) + 
  geom_col() +
  labs(
    title = "Mean monthly income per education",
    x = "Education",
    y = "Mean monthly income"
  ) +
  theme_minimal() +
  theme(text = element_text(size=10))+
  NULL

Education_median_income_bar <- ggplot(hr_cleaned, aes(
    x = education, 
    y = median(monthly_income
    ))) + 
  geom_col() +
  labs(
    title = "Median monthly income per education",
    x = "Education",
    y = "Median monthly income") +
  theme_minimal() +
  theme(text = element_text(size=10))+
  NULL

Education_mean_income_bar
Education_median_income_bar

```

7. Plot the distribution of income by education level. Use a facet_wrap and a theme from `ggthemes`

```{r distribution_by_education, fig.width=10}

Monthly_income_education_distr <- ggplot(hr_cleaned, aes(
    x = monthly_income
  )) + 
  geom_histogram() + 
  facet_wrap(~education,ncol=2) + 
  labs(
    title = "Distribution of income by education",
    x = "Education"
  ) +
  theme_economist_white() +
  NULL

Monthly_income_education_distr

```


1. Plot income vs age, faceted by `job_role`
```{r Income_vs_age_by_jobrole}

Income_vs_age_facet <- ggplot(hr_cleaned, aes(
    x = age, 
    y = monthly_income
  )) + 
  geom_col(width = 2) + 
  facet_wrap(~job_role) +
  labs(
    title = "Income vs. age by job role",
    x = "Age",
    y = "Monthly income"
  ) +
  theme_minimal() +
  NULL

Income_vs_age_facet

```


# Challenge 1: Replicating a chart

```{r challenge1, echo=FALSE, out.width="90%"}
knitr::include_graphics(here::here("images", "figure3.jpeg"), error = FALSE)
```


```{r challenge1_loading_CDC_Males, echo=FALSE}
cdc_dataset <- vroom("CDC_Males.csv")
```


```{r challenge1_CDC_males_plot}

library(viridis)
library(ggthemes)
library(hrbrthemes)
library(cowplot)



attach(cdc_dataset)

res <- cor.test(adjusted.suicide.White, adjusted.homicide.White, method = "spearman") #computation of the spearman method


cdc_dataset <- na.omit(cdc_dataset)

cdc_dataset_firearm <- filter(cdc_dataset, cdc_dataset$type == "Firearm") #Filtered out the non-firearm related deaths

CDC_Males_plot <- ggplot(cdc_dataset_firearm, aes(
      x = adjusted.suicide.White, 
      y = adjusted.homicide.White,
      size = cdc_dataset_firearm$average.pop.white, 
      label= ST, 
      fill= gun.house.prev.category)
      ) + 
  geom_point(aes(
      fill = gun.house.prev.category, 
      size = average.pop.white), 
      col = "black", 
      pch = 21, #shape
      ) + 
  scale_fill_manual( #legend
      values = c("#ffffb2", "#fecc5c", "#fd8d3c", "#e31a1c"), #different types of colours for legend
      name = "Gun ownership") + 
      scale_size(range= c(0.1,10),
      name = "White population",
      breaks = c(500000, 1500000, 3000000, 7000000), 
      labels = c("500 000", "1 500 000", "3 000 000", "7 000 000")
    ) + 
  ggrepel::geom_text_repel(size=5) + #State labels in graph
  labs(
      title="Relationship between the annual rates of firearm homicide and suicide among white men, by state, and reported
household firearm ownership, 2008 to 2016.",
      x="White Suicide Rate (per 100000 per Year)",
      y="White Homicide Rate (per 100 000 per Year)"
  ) + 
  draw_plot_label("Spearman correlation: 0.727 ", #Spearman legend inside the graph
      x=11.0,
      y=0.30,
      size=9) +
  guides(fill=guide_legend(override.aes=list(size=5))) #symbol size in the legend
  NULL

Formatted_CDC_Males_plot <- CDC_Males_plot + theme_minimal() +
  coord_cartesian( #used this to change the scale of the x and y axis
    xlim = c(0, 30), 
    ylim = c(0, 5)
  )+ 
  theme( #changed the legend size and colour
    legend.text = element_text( size = 12),
    legend.title = element_text(size = 14),
    legend.key=element_rect(fill = "white", colour = "white"), #replaced grey squares by white squares in the legend
    legend.key.size = unit(1, "cm"),
    legend.key.width = unit(0.5,"cm")) +
  NULL

Formatted_CDC_Males_plot

```


# Challenge 2: 2016 California Contributors plots


```{r challenge2, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "challenge2.png"), error = FALSE)
```


```{r, load_CA_data, warnings= FALSE, message=FALSE}

CA_contributors_2016 <- vroom("CA_contributors_2016.csv")

glimpse(CA_contributors_2016)
```
```{r loading_zipcodes}

zip_codes <- read_csv("zip_code_database.csv")

CA_contributors_2016$zip <- as.character(CA_contributors_2016$zip)

```


```{r glimpse_campaign}

campaign <- inner_join(CA_contributors_2016,zip_codes,by='zip')
glimpse(campaign)

```


```{r assigning_sum_contributions_percandidate}

Total_contb <-campaign %>% 
  group_by(cand_nm) %>% 
  summarise(total_amt = sum(contb_receipt_amt)) %>% 
  arrange(desc(total_amt))

```

```{r clinton_contb_per_city}

Clinton_plot <- ggplot(filter(campaign,cand_nm=="Clinton, Hillary Rodham" & state == "CA") %>%  
               group_by(primary_city) %>% 
               summarise(total_amt_county = sum(contb_receipt_amt)) %>%
               arrange(desc(total_amt_county)) %>%
               slice_max(total_amt_county,n=10),aes(
                 x=total_amt_county,
                 y=reorder(primary_city,total_amt_county))) +
  geom_col(fill="blue") + 
  labs(title = "Hillary Clinton") + 
  theme_clean() + 
  ylab(" ") + 
  xlab("Amount") + 
  scale_x_continuous(labels=scales::comma) +
  NULL

```

```{r Trump_contb_per_city}


Trump_plot <- ggplot(filter(campaign,cand_nm=="Trump, Donald J." & state == "CA") %>%  
                       group_by(primary_city) %>% 
                       summarise(total_amt_county = sum(contb_receipt_amt)) %>%
                       arrange(desc(total_amt_county)) %>%
                       slice_max(total_amt_county,n=10),aes(
                         x = total_amt_county,
                         y = reorder(primary_city,total_amt_county),)) +
  geom_col(fill= "red") +
  labs(title="Donald Trump") +
  theme_clean() + ylab(" ") +
  xlab("Amount") +
  scale_x_continuous(labels = scales::comma) +
  NULL

```

```{r cobining_plots,fig.width = 11, fig.asp = .72}

library(patchwork)

combined_plot <- Clinton_plot + Trump_plot 
  plot_annotation(title = "Where did the candidates raise most money?")

combined_plot

```

```{r top_10_candidates,fig.width = 30, fig.asp = .72}
#Attempting to loop plots
library(patchwork)

#selecting top 10 rows from Total_contb
top_10_candidates <- Total_contb %>%
  slice_max(total_amt,n = 10)

plots <- list()

#creating a loop to run plots
Candidate_plots <- 1
for(politicians in top_10_candidates$cand_nm){
  plots[[Candidate_plots]] <- ggplot(filter(campaign,cand_nm == politicians & state == "CA") %>%  
                         group_by(primary_city) %>% 
                         summarise(total_amt_county = sum(contb_receipt_amt)) %>%
                         arrange(desc(total_amt_county)) %>%
                         slice_max(total_amt_county,n=10),aes(
                           x = total_amt_county,
                           y = reorder(primary_city,total_amt_county)
                           ))+
    geom_col(fill= "blue") +
    labs(title=politicians) +
    theme_clean() + 
    ylab(" ") +
    xlab("Amount") +
    scale_x_continuous(labels = scales::comma)
Candidate_plots <- Candidate_plots + 1
}
wrap_plots(plots,ncol =5)

```

# Details

- Who did you collaborate with: Josephine Haag, Mehdi Lembarki Kadiri, Jun Xing, Peijun Xu, Melonica Mohapatra, Rick van der Linden
- Approximately how much time did you spend on this problem set: 20 hours
- What, if anything, gave you the most trouble: the formatting in challenge 1
